{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix\n",
    "\n",
    "Reference at [https://machinelearningmastery.com/confusion-matrix-machine-learning/]\n",
    "\n",
    "A confusion matrix is a technique for summarizing the performance of a classification algorithm.\n",
    "\n",
    "Classification accuracy alone can be misleading if you have an unequal number of observations in each class or if you have more than two classes in your dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Accuracy and its Limitations\n",
    "\n",
    "classification accuracy is the ratioo of correct predictions to total predictions made.\n",
    "\n",
    "```Python\n",
    "classification accuracy = correct predictions / total predictions\n",
    "```\n",
    "\n",
    "it is often presented as a percenteage by multiplying the result by 100\n",
    "\n",
    "```Python\n",
    "classification accuracy = correct predictions / total predictions * 100\n",
    "```\n",
    "\n",
    "Classification accuracy can also easily be turned into misclassification rate or error rate by inverting the value, such as:\n",
    "``` Python\n",
    "error rate = (1 - (correct predictions / total predictions)) * 100\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main problem with classification accuracy is that it hides the detail you need better understand the performance of your classification model. There are two examples where you are most likely to encouter this problem:\n",
    "1. When you are data has more than 2 classes. With 3 or more classes you may get a classification accuracy of 80%, but you don't know if that is because all classes are being predicted equally well or whether one or two classes are being neglected by the model.\n",
    "2. When your data does not have an even number of classes. You may achieve accuracy of 90% or more, but this is not a good score if 90 records for every 100 belong to one class and you can achieve this score by always predicting the most common class value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is a Confusion Matrix?\n",
    "\n",
    "A confusion matrix is a summary of prediction results on a classification problem.\n",
    "\n",
    "The number of correct and incorrect predictions are summarized with count values and broken down by each class. this is the key to the confusion matrix.\n",
    "\n",
    "<b><center>The confusion matrix shows the ways in which your classification model is confused when it makes predictions.</center></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to calculate a Confusion Matrix\n",
    "\n",
    "Below is the process for calculating a confusion matrix.\n",
    "1. You need a test dataset or validation dataset with expected outcome values.\n",
    "2. Make a prediction for each row in your test dataset.\n",
    "3. From the expected outcomes and predictions count:\n",
    "\n",
    "    3.1. The number of corrent predictions for each class.\n",
    "    \n",
    "    3.2. The number of incorect prediction for each class, organized by the clas that was predicted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two-class problems are special\n",
    "\n",
    "In a two-class problem, we are often looking to discriminate between observations with a specific outcome, from normal observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this way, we can assign the event row as \"_possitive_\" and the no-event row as \"_negative_\". We can then assign the event column of predictions as \"_true_\" and the no-event as \"_false_\".\n",
    "\n",
    "This gives us:\n",
    "* \"__true positive__\" for correctly predicted event values\n",
    "* \"__false positive__\" for incorrectly predicted event values\n",
    "* \"__true negative__\" for correctly predicted no-event values\n",
    "* \"__false negative__\" for incorrectly predicted no-event values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code exampels of the Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4 2]\n",
      " [1 3]]\n"
     ]
    }
   ],
   "source": [
    "# example of a confusion matrix in Python\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "expected = [1,1,0,1,0,0,1,0,0,0]\n",
    "predicted = [1,0,0,1,0,0,1,1,1,0]\n",
    "results = confusion_matrix(expected, predicted)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
